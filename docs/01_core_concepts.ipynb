{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Concepts: Pragmatic Functional Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers the foundational concepts of this blueprint. Each concept is a building block for writing robust, maintainable, and type-safe Python applications.\n",
    "\n",
    "**Key Principle: Executable Documentation**\n",
    "Every code example in this notebook is a mini-test. It ends with `assert` statements that prove its correctness. If you can run this notebook from top to bottom without any `AssertionError`, you can be confident that the examples work as described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Validation with `Pydantic` as a \"Boundary Guard\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Problem:** Your application's core logic should be a safe, predictable, and strongly-typed world. However, the outside world (APIs, databases, user input) is messy and unpredictable. How do you protect your core from malformed data?\n",
    "\n",
    "**The Solution:** We use `Pydantic` models as a \"Boundary Guard\". At the edge of our application (e.g., in an API endpoint), we parse external data into a Pydantic model. If the data is valid, we get a clean, typed object to work with. If it's invalid, Pydantic raises a descriptive error, stopping bad data from ever entering our system.\n",
    "\n",
    "### Best Practice: Using `typing.Annotated`\n",
    "\n",
    "We prefer using `typing.Annotated` to declare validation rules. This is a modern Python feature (PEP 593) that cleanly separates the type (`str`) from the metadata (`Field(...)`). It makes the code more readable and interoperable with other tools that might also use annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pydantic model created successfully from valid data.\n",
      "✅ Pydantic correctly raised a ValidationError for invalid data.\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a user, using Annotated for clean metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    id: int\n",
    "    name: Annotated[str, Field(min_length=2, description=\"The user's name\")]\n",
    "    age: Annotated[int, Field(gt=0, le=120, description=\"Age in years\")]\n",
    "\n",
    "\n",
    "# --- Verification ---\n",
    "\n",
    "# 1. Test the successful case\n",
    "valid_data = {\"id\": 1, \"name\": \"Alice\", \"age\": 30}\n",
    "user = User.model_validate(valid_data)\n",
    "\n",
    "assert user.id == 1\n",
    "assert user.name == \"Alice\"\n",
    "assert user.age == 30\n",
    "\n",
    "print(\"✅ Pydantic model created successfully from valid data.\")\n",
    "\n",
    "# 2. Test the validation failure case\n",
    "invalid_data = {\"id\": 2, \"name\": \"B\", \"age\": 200}  # Name too short, age too high\n",
    "\n",
    "raised_exception = None\n",
    "try:\n",
    "    User.model_validate(invalid_data)\n",
    "except ValidationError as e:\n",
    "    raised_exception = e\n",
    "\n",
    "assert raised_exception is not None, \"ValidationError was not raised for invalid data!\"\n",
    "\n",
    "error_messages = str(raised_exception)\n",
    "assert \"name\" in error_messages\n",
    "assert \"String should have at least 2 characters\" in error_messages\n",
    "assert \"age\" in error_messages\n",
    "assert \"Input should be less than or equal to 120\" in error_messages\n",
    "\n",
    "print(\"✅ Pydantic correctly raised a ValidationError for invalid data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Error Handling with `returns.Result`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Problem:** Traditional error handling with `try...except` blocks can make business logic hard to follow. It mixes the \"happy path\" with error-handling code and makes it unclear which functions can fail and which can't.\n",
    "\n",
    "**The Solution:** We use the `Result` monad from the `returns` library, a pattern often called \"Railway Oriented Programming\".\n",
    "- A function that can fail returns either `Success(value)` or `Failure(error)`.\n",
    "- The return type `Result[SuccessType, FailureType]` makes it **explicit in the type signature** that the operation can fail.\n",
    "- This forces the caller to handle the failure case, leading to more robust and predictable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ `parse_user_id` returned Success for valid input.\n",
      "✅ `parse_user_id` returned Failure for invalid format.\n",
      "✅ `parse_user_id` returned Failure for invalid value.\n"
     ]
    }
   ],
   "source": [
    "from returns.result import Failure, Result, Success\n",
    "\n",
    "\n",
    "def parse_user_id(raw_id: str) -> Result[int, str]:\n",
    "    \"\"\"Tries to parse a string into a positive integer ID.\"\"\"\n",
    "    if not raw_id.isdigit():\n",
    "        return Failure(f\"Invalid format: '{raw_id}' is not a digit.\")\n",
    "\n",
    "    user_id = int(raw_id)\n",
    "    if user_id <= 0:\n",
    "        return Failure(f\"Invalid value: ID {user_id} must be positive.\")\n",
    "\n",
    "    return Success(user_id)\n",
    "\n",
    "\n",
    "# --- Verification ---\n",
    "\n",
    "# 1. Test the Success case\n",
    "success_result = parse_user_id(\"123\")\n",
    "assert isinstance(success_result, Success)\n",
    "assert success_result.unwrap() == 123\n",
    "print(\"✅ `parse_user_id` returned Success for valid input.\")\n",
    "\n",
    "# 2. Test the Failure case (format)\n",
    "failure_result_format = parse_user_id(\"abc\")\n",
    "assert isinstance(failure_result_format, Failure)\n",
    "assert \"Invalid format\" in failure_result_format.failure()\n",
    "print(\"✅ `parse_user_id` returned Failure for invalid format.\")\n",
    "\n",
    "# 3. Test the Failure case (value)\n",
    "failure_result_value = parse_user_id(\"0\")\n",
    "assert isinstance(failure_result_value, Failure)\n",
    "assert \"must be positive\" in failure_result_value.failure()\n",
    "print(\"✅ `parse_user_id` returned Failure for invalid value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Functional Pipelines with `returns.pipe`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Problem:** Chaining multiple data transformation steps can lead to deeply nested function calls that are hard to read from inside-out, or a series of difficult-to-track intermediate variables.\n",
    "\n",
    "**The Solution:** We use `returns.pipe` to create a clean, readable, left-to-right data processing pipeline. It takes a starting value and passes it through a series of functions, where the output of one function becomes the input for the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline: '  This is a Long String of Text   ' to '\"this is a !\"'\n",
      "✅ Pipeline correctly working\n"
     ]
    }
   ],
   "source": [
    "from returns.pipeline import pipe\n",
    "\n",
    "\n",
    "# Define a few simple, pure functions for our pipeline\n",
    "def clean_text(text: str) -> str:\n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "def truncate_text(text: str) -> str:\n",
    "    return text[:10]\n",
    "\n",
    "\n",
    "def emphasize_text(text: str) -> str:\n",
    "    return f'\"{text}!\"'\n",
    "\n",
    "\n",
    "# The input data\n",
    "raw_input = \"  This is a Long String of Text   \"\n",
    "\n",
    "# Use pipe to compose the functions into a pipeline\n",
    "processed_text = pipe(clean_text, truncate_text, emphasize_text)(raw_input)  # pyright: ignore\n",
    "\n",
    "# --- Verification ---\n",
    "print(f\"Pipeline: '{raw_input}' to '{processed_text}'\")\n",
    "expected_output = '\"this is a !\"'\n",
    "assert processed_text == expected_output\n",
    "print(\"✅ Pipeline correctly working\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Structured Logging with `Loguru`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Problem:** Python's built-in logging is powerful but requires a lot of boilerplate to set up. Getting useful, colored, and structured logs can be a chore.\n",
    "\n",
    "**The Solution:** We use `Loguru` for a vastly improved developer experience. It provides sensible defaults, is easy to configure, and works out-of-the-box.\n",
    "\n",
    "### Configuration via `.env`\n",
    "\n",
    "This project configures Loguru based on environment variables defined in your `.env` file. You can control the log level and whether logs are written to a file without changing any code. See `.env.example` for details:\n",
    "\n",
    "```dotenv\n",
    "# .env.example\n",
    "LOG_LEVEL=\"INFO\"\n",
    "LOG_TO_FILE=\"FALSE\"\n",
    "```\n",
    "\n",
    "### Example Usage\n",
    "The code below demonstrates basic logging. Since we can't easily assert on `stderr` output in a notebook, this cell is for demonstration. The `setup_logging` function is what you would call once at the start of your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__:<module>:19\u001b[0m - \u001b[34m\u001b[1mThis is a debug message. Useful for developers.\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[36m__main__:<module>:20\u001b[0m - \u001b[1mApplication is starting up...\u001b[0m\n",
      "\u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__:<module>:21\u001b[0m - \u001b[32m\u001b[1mA task was completed successfully.\u001b[0m\n",
      "\u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__:<module>:22\u001b[0m - \u001b[33m\u001b[1mSomething looks a bit strange, but it's not an error.\u001b[0m\n",
      "\u001b[31m\u001b[1mERROR   \u001b[0m | \u001b[36m__main__:<module>:23\u001b[0m - \u001b[31m\u001b[1mAn error occurred! This needs attention.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Loguru demonstrated various log levels.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "\n",
    "# This is a simplified version of the project's logging setup\n",
    "def setup_simple_logging(level=\"INFO\"):\n",
    "    logger.remove()\n",
    "    logger.add(\n",
    "        sys.stderr,\n",
    "        level=level.upper(),\n",
    "        format=\"<level>{level: <8}</level> | <cyan>{name}:{function}:{line}</cyan> - <level>{message}</level>\",\n",
    "        colorize=True,\n",
    "    )\n",
    "\n",
    "\n",
    "setup_simple_logging(level=\"DEBUG\")\n",
    "\n",
    "logger.debug(\"This is a debug message. Useful for developers.\")\n",
    "logger.info(\"Application is starting up...\")\n",
    "logger.success(\"A task was completed successfully.\")\n",
    "logger.warning(\"Something looks a bit strange, but it's not an error.\")\n",
    "logger.error(\"An error occurred! This needs attention.\")\n",
    "\n",
    "# No assert here, this is for visual inspection of the output above this cell.\n",
    "print(\"\\n✅ Loguru demonstrated various log levels.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Focused Debugging: Filtering Logs\n",
    "\n",
    "A powerful feature of Loguru is the ability to filter logs to focus on a specific part of your application. You don't configure this in the `.env` file, but directly in your logging setup code (e.g., `src/core/logging_config.py`) during a debugging session.\n",
    "\n",
    "**Example: See only `DEBUG` messages from `my_module`**\n",
    "```python\n",
    "# Show only messages with level DEBUG from any module named 'my_module' or its children.\n",
    "logger.add(\"debug.log\", level=\"DEBUG\", filter=\"my_module\")\n",
    "```\n",
    "\n",
    "**Example: Ignore a noisy module**\n",
    "```python\n",
    "# Show all INFO logs, except for those coming from the noisy 'noisy_library'.\n",
    "logger.add(\"filtered.log\", level=\"INFO\", filter=lambda record: \"noisy_library\" not in record[\"name\"])\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-starter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
